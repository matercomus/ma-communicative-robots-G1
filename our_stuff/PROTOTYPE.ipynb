{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DslEWtJc7P9C"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca_8Nxy6MFbt",
        "outputId": "e2a505de-5805-4e88-e8f1-68c3413aba80",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: cltl.combot in /home/matt/.local/lib/python3.12/site-packages (1.1.0)\n",
            "Requirement already satisfied: emissor in /home/matt/.local/lib/python3.12/site-packages (from cltl.combot) (0.0.dev6)\n",
            "Requirement already satisfied: numpy~=1.20 in /home/matt/.local/lib/python3.12/site-packages (from emissor->cltl.combot) (1.26.4)\n",
            "Requirement already satisfied: marshmallow~=3.11 in /home/matt/.local/lib/python3.12/site-packages (from emissor->cltl.combot) (3.23.1)\n",
            "Requirement already satisfied: marshmallow-dataclass~=8.4 in /home/matt/.local/lib/python3.12/site-packages (from emissor->cltl.combot) (8.6.1)\n",
            "Requirement already satisfied: marshmallow-enum~=1.5 in /home/matt/.local/lib/python3.12/site-packages (from emissor->cltl.combot) (1.5.1)\n",
            "Requirement already satisfied: marshmallow-union~=0.1 in /home/matt/.local/lib/python3.12/site-packages (from emissor->cltl.combot) (0.1.15.post1)\n",
            "Requirement already satisfied: rdflib~=6.0 in /home/matt/.local/lib/python3.12/site-packages (from emissor->cltl.combot) (6.3.2)\n",
            "Requirement already satisfied: simplejson~=3.17 in /home/matt/.local/lib/python3.12/site-packages (from emissor->cltl.combot) (3.19.2)\n",
            "Requirement already satisfied: typeguard~=2.13 in /home/matt/.local/lib/python3.12/site-packages (from emissor->cltl.combot) (2.13.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/lib/python3.12/site-packages (from marshmallow~=3.11->emissor->cltl.combot) (24.1)\n",
            "Requirement already satisfied: typing-inspect<1.0,>=0.8.0 in /home/matt/.local/lib/python3.12/site-packages (from marshmallow-dataclass~=8.4->emissor->cltl.combot) (0.9.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/matt/.local/lib/python3.12/site-packages (from rdflib~=6.0->emissor->cltl.combot) (0.6.1)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/matt/.local/lib/python3.12/site-packages (from rdflib~=6.0->emissor->cltl.combot) (3.1.2)\n",
            "Requirement already satisfied: six in /usr/lib/python3.12/site-packages (from isodate<0.7.0,>=0.6.0->rdflib~=6.0->emissor->cltl.combot) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/matt/.local/lib/python3.12/site-packages (from typing-inspect<1.0,>=0.8.0->marshmallow-dataclass~=8.4->emissor->cltl.combot) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/lib/python3.12/site-packages (from typing-inspect<1.0,>=0.8.0->marshmallow-dataclass~=8.4->emissor->cltl.combot) (4.12.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Matt\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath('../combots_venv/lib/python3.12/site-packages'))\n",
        "%pip install cltl.combot --break-system-packages\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "# Construct the relative path to the .env file\n",
        "env_path = os.path.join(current_dir, '../.env')\n",
        "# Load the .env file\n",
        "load_dotenv(env_path)\n",
        "\n",
        "\n",
        "# OpenAI API Key\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gfSVLt26MFbt",
        "outputId": "29eaca55-6199-4cb8-ee44-053678820d4a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting cltl.combot\n",
            "  Downloading cltl.combot-1.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting emissor (from cltl.combot)\n",
            "  Downloading emissor-0.0.dev6.tar.gz (347 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.4/347.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy~=1.20 in /usr/local/lib/python3.10/dist-packages (from emissor->cltl.combot) (1.26.4)\n",
            "Collecting marshmallow~=3.11 (from emissor->cltl.combot)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting marshmallow-dataclass~=8.4 (from emissor->cltl.combot)\n",
            "  Downloading marshmallow_dataclass-8.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting marshmallow-enum~=1.5 (from emissor->cltl.combot)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting marshmallow-union~=0.1 (from emissor->cltl.combot)\n",
            "  Downloading marshmallow_union-0.1.15.post1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting rdflib~=6.0 (from emissor->cltl.combot)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting simplejson~=3.17 (from emissor->cltl.combot)\n",
            "  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting typeguard~=2.13 (from emissor->cltl.combot)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow~=3.11->emissor->cltl.combot) (24.2)\n",
            "Collecting typing-inspect>=0.9.0 (from marshmallow-dataclass~=8.4->emissor->cltl.combot)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "INFO: pip is looking at multiple versions of marshmallow-dataclass to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting marshmallow-dataclass~=8.4 (from emissor->cltl.combot)\n",
            "  Downloading marshmallow_dataclass-8.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "  Downloading marshmallow_dataclass-8.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow-dataclass~=8.4->emissor->cltl.combot) (4.12.2)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib~=6.0->emissor->cltl.combot)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib~=6.0->emissor->cltl.combot) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib~=6.0->emissor->cltl.combot) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.9.0->marshmallow-dataclass~=8.4->emissor->cltl.combot)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading cltl.combot-1.1.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow_dataclass-8.6.1-py3-none-any.whl (18 kB)\n",
            "Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading marshmallow_union-0.1.15.post1-py2.py3-none-any.whl (4.6 kB)\n",
            "Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: emissor\n",
            "  Building wheel for emissor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emissor: filename=emissor-0.0.dev6-py3-none-any.whl size=28072 sha256=e0270c07fd45427c2bbd36ec604abca7507fcf6c10f68021eeb966b439ad9947\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/30/5b/e488c7a890017159ea29de3613bf92e37a1d4154db2e7b512c\n",
            "Successfully built emissor\n",
            "Installing collected packages: typeguard, simplejson, mypy-extensions, marshmallow, isodate, typing-inspect, rdflib, marshmallow-union, marshmallow-enum, marshmallow-dataclass, emissor, cltl.combot\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cltl.combot-1.1.0 emissor-0.0.dev6 isodate-0.6.1 marshmallow-3.23.1 marshmallow-dataclass-8.6.1 marshmallow-enum-1.5.1 marshmallow-union-0.1.15.post1 mypy-extensions-1.0.0 rdflib-6.3.2 simplejson-3.19.3 typeguard-2.13.3 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <progress value='100' max=\"100\", style='width: 100%'>\n",
              "                100\n",
              "            </progress>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Colab\n",
        "!pip install --upgrade ai2thor --quiet\n",
        "!pip install ai2thor-colab prior --upgrade &> /dev/null\n",
        "!pip install python-dotenv\n",
        "%pip install cltl.combot --break-system-packages\n",
        "import os\n",
        "os.system('apt-get install xvfb')\n",
        "import ai2thor_colab\n",
        "ai2thor_colab.start_xserver()\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv()\n",
        "\n",
        "# OpenAI API Key\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CIeQE8989ndG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5507f6-42de-4041-afe8-700cf5aa9fdc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI2-THOR WARNING] There has been an update to ProcTHOR-10K that must be used with AI2-THOR version 5.0+. To use the new version of ProcTHOR-10K, please update AI2-THOR to version 5.0+ by running:\n",
            "    pip install --upgrade ai2thor\n",
            "Alternatively, to downgrade to the old version of ProcTHOR-10K, run:\n",
            "   prior.load_dataset(\"procthor-10k\", revision=\"ab3cacd0fc17754d4c080a3fd50b18395fae8647\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading train: 100%|██████████| 10000/10000 [00:08<00:00, 1177.97it/s]\n",
            "Loading val: 100%|██████████| 1000/1000 [00:00<00:00, 2518.56it/s]\n",
            "Loading test: 100%|██████████| 1000/1000 [00:00<00:00, 2950.32it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict(\n",
              "    train=Dataset(\n",
              "    dataset=procthor-dataset,\n",
              "    size=10000,\n",
              "    split=train\n",
              "),\n",
              "    val=Dataset(\n",
              "    dataset=procthor-dataset,\n",
              "    size=1000,\n",
              "    split=val\n",
              "),\n",
              "    test=Dataset(\n",
              "    dataset=procthor-dataset,\n",
              "    size=1000,\n",
              "    split=test\n",
              ")\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import prior\n",
        "\n",
        "dataset = prior.load_dataset(\"procthor-10k\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cPurgiJ4U-C5"
      },
      "outputs": [],
      "source": [
        "house = dataset[\"train\"][11] # CHOOSE HOUSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1Oa8abqULvzA"
      },
      "outputs": [],
      "source": [
        "from ai2thor.controller import Controller\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xv7Vm8BzR9dU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9296f49-dcb3-4a9d-f0cf-8fe299b4e662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "thor-Linux64-f0825767cd50d69f666c7f282e54abfe58f1e917.zip: [ \u001b[38;2;0;255;0m100%\u001b[39m  31.7 MiB/s]  of 769.MB\n"
          ]
        }
      ],
      "source": [
        "controller = Controller(scene=house, visibilityDistance=10, width=750, height=750)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "event = controller.step(action=\"GetReachablePositions\")\n",
        "reachable_positions = event.metadata[\"actionReturn\"]"
      ],
      "metadata": {
        "id": "w51BWkAXBrqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openaiapi import analyze_prompt, analyze_image\n",
        "from utils import numpy_to_base64\n",
        "\n",
        "frame = controller.last_event.frame\n",
        "base64_string = numpy_to_base64(frame)"
      ],
      "metadata": {
        "id": "935AYZpDCaLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FUNCTIONS"
      ],
      "metadata": {
        "id": "-Xr-ZujnCb_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UvOXK5C2-N5v"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def teleport_in_front_of_object(controller, object_position, reachable_positions, distance=1.0):\n",
        "  \"\"\"Teleports the agent to the closest reachable position in front of an object.\n",
        "\n",
        "  Args:\n",
        "    controller: The AI2Thor controller.\n",
        "    object_position: The position of the target object.\n",
        "    reachable_positions: A list of reachable positions in the scene.\n",
        "    distance: The desired distance in front of the object.\n",
        "\n",
        "  Returns:\n",
        "    The event after teleporting.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate the target position in front of the object\n",
        "  target_position = {\n",
        "      \"x\": object_position[\"x\"] - distance,\n",
        "      \"y\": object_position[\"y\"],\n",
        "      \"z\": object_position[\"z\"]\n",
        "  }\n",
        "\n",
        "  # Find the closest reachable position\n",
        "  closest_position = None\n",
        "  min_distance = float('inf')\n",
        "\n",
        "  for position in reachable_positions:\n",
        "    dist = math.sqrt((position[\"x\"] - target_position[\"x\"])**2 +\n",
        "                     (position[\"z\"] - target_position[\"z\"])**2)\n",
        "    if dist < min_distance:\n",
        "      min_distance = dist\n",
        "      closest_position = position\n",
        "\n",
        "# Calculate rotation towards the object\n",
        "  dx = object_position[\"x\"] - closest_position[\"x\"]\n",
        "  dz = object_position[\"z\"] - closest_position[\"z\"]\n",
        "  rotation = math.degrees(math.atan2(dx, dz))\n",
        "\n",
        "  # Teleport and rotate\n",
        "  event = controller.step(action=\"Teleport\", position=closest_position, rotation=rotation)\n",
        "\n",
        "  return event  # Return the event after adjusting view angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nKgXHQjzOwmK"
      },
      "outputs": [],
      "source": [
        "def get_object_positions(controller, matched_object):\n",
        "  \"\"\"\n",
        "  Finds the positions of all visible objects of a specific type.\n",
        "\n",
        "  Args:\n",
        "    controller: The AI2Thor controller.\n",
        "    matched_object: The type of object to find (e.g., \"Painting\", \"Chair\", \"Table\").\n",
        "\n",
        "  Returns:\n",
        "    A list of positions for the specified object type.\n",
        "  \"\"\"\n",
        "  visible_objects = [obj for obj in controller.last_event.metadata[\"objects\"] if obj[\"visible\"]]\n",
        "  objects_of_interest = [obj for obj in visible_objects if obj[\"objectType\"] == matched_object]\n",
        "  object_positions = []\n",
        "  for obj in objects_of_interest:\n",
        "      #print(obj[\"name\"], obj[\"position\"])\n",
        "      object_positions.append(obj[\"position\"])\n",
        "  return object_positions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def interactive_object_match(api_key: str, human_object_description: str, unique_object_list: list, HUMAN: str, AGENT: str, leolaniClient):\n",
        "    \"\"\"\n",
        "    Interactively matches a human description of an object to one from a given list using an LLM.\n",
        "    The function continues to refine guesses based on user confirmation or denial.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): The API key for accessing the LLM.\n",
        "        human_object_description (str): A description of the object to match.\n",
        "        unique_object_list (list): The list of unique objects to match against.\n",
        "\n",
        "    Returns:\n",
        "        str: The confirmed object from the user.\n",
        "        list: The matched object(s) from the list based on the LLM's response.\n",
        "    \"\"\"\n",
        "    def ask_llm(description: str, objects: list) -> str:\n",
        "        \"\"\"Helper function to query the LLM for matching the description.\"\"\"\n",
        "        object_list_str = \", \".join(objects)\n",
        "        prompt = (\n",
        "            f\"Imagine you are tasked with identifying an object from a given list based on its description. \"\n",
        "            f\"The list of objects is: {object_list_str}. \"\n",
        "            f\"Your task is to match the following description to one or more objects from the list: \\n\"\n",
        "            f\"'{description}'\\n\\n\"\n",
        "            \"If you have a single best guess, respond with: 'To be sure, would you describe your object as {object}?'\\n\"\n",
        "            \"If you are unsure and need clarification between a few options, respond with: \"\n",
        "            \"'To be sure, would you describe your object as {object1} or {object2}?'\"\n",
        "            \"Only use objects from the list.\"\n",
        "        )\n",
        "        # Make sure the response is extracted correctly from the LLM\n",
        "        llm_response = analyze_prompt(api_key=api_key, prompt=prompt)\n",
        "\n",
        "        if isinstance(llm_response, tuple):\n",
        "            llm_response = llm_response[0]\n",
        "\n",
        "        if isinstance(llm_response, list) and llm_response:  # Check if it's a non-empty list\n",
        "            llm_response = llm_response[0]  # Access the first element if it's a list\n",
        "\n",
        "        if isinstance(llm_response, dict) and \"choices\" in llm_response and llm_response[\"choices\"]:\n",
        "            return llm_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        return llm_response  # Return raw response if format is unexpected\n",
        "\n",
        "    current_description = human_object_description\n",
        "\n",
        "    while True:\n",
        "        # Query the LLM for a guess\n",
        "        response = ask_llm(current_description, unique_object_list)\n",
        "        leolaniClient._add_utterance(AGENT, response)\n",
        "        print(f\"{AGENT}>{response}\")\n",
        "\n",
        "        # Extract the matched object(s) from the response\n",
        "        matched_objects = re.findall(r\"\\b(\" + \"|\".join(map(re.escape, unique_object_list)) + r\")\\b\", response)\n",
        "\n",
        "        # Ask the user for confirmation or denial\n",
        "        confirmation_prompt = \"Is this correct? (yes/no): \"\n",
        "        leolaniClient._add_utterance(AGENT, confirmation_prompt)\n",
        "        print(f\"{AGENT}>{confirmation_prompt}\")\n",
        "        user_input = input().strip().lower()\n",
        "        leolaniClient._add_utterance(HUMAN, user_input)\n",
        "        print(f\"{HUMAN}>{user_input}\")\n",
        "\n",
        "        if user_input == \"yes\":\n",
        "            success_message = \"Great! Object successfully matched.\"\n",
        "            leolaniClient._add_utterance(AGENT, success_message)\n",
        "            print(f\"{AGENT}>{success_message}\")\n",
        "            return matched_objects[0] if len(matched_objects) == 1 else matched_objects\n",
        "        elif user_input == \"no\":\n",
        "            refine_message = \"Let's refine the search. Can you provide more details or clarify the description?\"\n",
        "            leolaniClient._add_utterance(AGENT, refine_message)\n",
        "            print(f\"{AGENT}>{refine_message}\")\n",
        "            clarifying_question = input().strip()\n",
        "            leolaniClient._add_utterance(HUMAN, clarifying_question)\n",
        "            print(f\"{HUMAN}>{clarifying_question}\")\n",
        "            current_description += \" \" + clarifying_question\n",
        "        else:\n",
        "            error_message = \"Please respond with 'yes' or 'no'.\"\n",
        "            leolaniClient._add_utterance(AGENT, error_message)\n",
        "            print(f\"{AGENT}>{error_message}\")\n"
      ],
      "metadata": {
        "id": "pbYQyvUq6eCo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_object_list = [\n",
        "    \"AlarmClock\", \"AluminumFoil\", \"Apple\", \"ArmChair\", \"BaseballBat\", \"BasketBall\",\n",
        "    \"Bathtub\", \"BathtubBasin\", \"Bed\", \"Blinds\", \"Book\", \"Boots\", \"Bottle\", \"Bowl\",\n",
        "    \"Box\", \"Bread\", \"ButterKnife\", \"Cabinet\", \"Candle\", \"CD\", \"CellPhone\", \"Chair\",\n",
        "    \"Cloth\", \"CoffeeMachine\", \"CoffeeTable\", \"CounterTop\", \"CreditCard\", \"Cup\",\n",
        "    \"Curtains\", \"Desk\", \"DeskLamp\", \"Desktop\", \"DiningTable\", \"DishSponge\", \"DogBed\",\n",
        "    \"Drawer\", \"Dresser\", \"Dumbbell\", \"Egg\", \"Faucet\", \"Floor\", \"FloorLamp\",\n",
        "    \"Footstool\", \"Fork\", \"Fridge\", \"GarbageBag\", \"GarbageCan\", \"HandTowel\",\n",
        "    \"HandTowelHolder\", \"HousePlant\", \"Kettle\", \"KeyChain\", \"Knife\", \"Ladle\", \"Laptop\",\n",
        "    \"LaundryHamper\", \"Lettuce\", \"LightSwitch\", \"Microwave\", \"Mirror\", \"Mug\",\n",
        "    \"Newspaper\", \"Ottoman\", \"Painting\", \"Pan\", \"PaperTowelRoll\", \"Pen\", \"Pencil\",\n",
        "    \"PepperShaker\", \"Pillow\", \"Plate\", \"Plunger\", \"Poster\", \"Pot\", \"Potato\",\n",
        "    \"RemoteControl\", \"RoomDecor\", \"Safe\", \"SaltShaker\", \"ScrubBrush\", \"Shelf\",\n",
        "    \"ShelvingUnit\", \"ShowerCurtain\", \"ShowerDoor\", \"ShowerGlass\", \"ShowerHead\",\n",
        "    \"SideTable\", \"Sink\", \"SinkBasin\", \"SoapBar\", \"SoapBottle\", \"Sofa\", \"Spatula\",\n",
        "    \"Spoon\", \"SprayBottle\", \"Statue\", \"Stool\", \"StoveBurner\", \"StoveKnob\",\n",
        "    \"TableTopDecor\", \"TargetCircle\", \"TeddyBear\", \"Television\", \"TennisRacket\",\n",
        "    \"TissueBox\", \"Toaster\", \"Toilet\", \"ToiletPaper\", \"ToiletPaperHanger\", \"Tomato\",\n",
        "    \"Towel\", \"TowelHolder\", \"TVStand\", \"VacuumCleaner\", \"Vase\", \"Watch\",\n",
        "    \"WateringCan\", \"Window\", \"WineBottle\"\n",
        "]"
      ],
      "metadata": {
        "id": "Oi4GNic-9wge"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DNPvIi-9ndS"
      },
      "source": [
        "# Test Interaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jsOTU7pCVdcA"
      },
      "outputs": [],
      "source": [
        "# adding to the system path\n",
        "import sys\n",
        "sys.path.insert(0, os.path.abspath('../emissor_chat'))\n",
        "\n",
        "from leolani_client import LeolaniChatClient, Action\n",
        "emissor_path = \"./emissor\"\n",
        "AGENT=\"Ai2Thor\"\n",
        "HUMAN = \"Human\"\n",
        "leolaniClient = LeolaniChatClient(emissor_path=emissor_path, agent=AGENT, human=HUMAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezATi5dbMFb3",
        "outputId": "2bdb037e-7b54-4cb0-db8e-db7616043620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ai2Thor>Hi Human. What do you see in the room?\n"
          ]
        }
      ],
      "source": [
        "utterance = f\"Hi {HUMAN}. What do you see in the room?\"\n",
        "print(AGENT+\">\"+utterance)\n",
        "leolaniClient._add_utterance(AGENT, utterance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6jOykszMFb3"
      },
      "outputs": [],
      "source": [
        "# grab img of an item to look for\n",
        "\n",
        "#example: look for a tv in a room\n",
        "#event = controller.step(action=\"Teleport\", position={'x': 2.75, 'y': 0.9009997844696045, 'z': 1.0}  with rotation 209)\n",
        "#Image.fromarray(event.frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "up-KwAtd9ndS"
      },
      "outputs": [],
      "source": [
        "human_room_description = \"there is a table. 5 chairs. wthere is a window. its probably a living room.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyrWK2lpMFb3",
        "outputId": "9c345a2c-72de-4bdc-e2b0-8fa3bc42830c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human>there is a table. 5 chairs. wthere is a window. its probably a living room.\n"
          ]
        }
      ],
      "source": [
        "print(HUMAN+\">\"+human_room_description)\n",
        "leolaniClient._add_utterance(HUMAN, human_room_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "J0CAYrjg9ndT"
      },
      "outputs": [],
      "source": [
        "# claryfying questions\n",
        "claryfying_questions_response = analyze_prompt(api_key=api_key, model = \"gpt-4o-mini\", prompt=f\"Imagine you are a robot who needs to be on a exact location as the point of view that the human has. After a while, the human can no longer see this image. The human will most likely describe a room from memory. The human will most likely describe a few objects and maybe some other attributes, like colours of objects. Your task is to ask claryfing questions about the room and objects so that you (the robot) has the highest chance of finding where the human was standing. Remember, ask the questions as if you were directly talking to the human. Try not to ask for too much details and dont ask for too much; remember, the human has to describe the image from memory, so only ask what you deem most important. \\n Human description: {human_room_description}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66IEJwOnMFb4",
        "outputId": "29e1d416-d0e6-4612-faef-d497a96cd551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ai2Thor>Thank you for the description! To help me locate where you were standing, could you tell me the color of the table and the chairs? Also, what size is the window, and where is it positioned in the room?\n"
          ]
        }
      ],
      "source": [
        "utterance = claryfying_questions_response[0][\"choices\"][0][\"message\"][\"content\"]\n",
        "print(AGENT+\">\"+utterance)\n",
        "leolaniClient._add_utterance(AGENT, utterance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zJDwKz1MFb4",
        "outputId": "1b474d2e-dce3-4486-d914-a3ac90d14695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human>The table is blue, chairs are all black. The window is on the left wall in the same corner as th balcony doors.\n"
          ]
        }
      ],
      "source": [
        "human_room_description_clarified = \"The table is blue, chairs are all black. The window is on the left wall in the same corner as th balcony doors.\"\n",
        "print(HUMAN+\">\"+human_room_description_clarified)\n",
        "leolaniClient._add_utterance(HUMAN, human_room_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vn0lgHmMFb4",
        "outputId": "d68054aa-600e-4682-d650-2515160c9d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ai2Thor>Describe the object I should look for.\n"
          ]
        }
      ],
      "source": [
        "utterance = \"Describe the object I should look for.\"\n",
        "print(AGENT+\">\"+utterance)\n",
        "leolaniClient._add_utterance(AGENT, utterance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TIhZRTY_LRUS"
      },
      "outputs": [],
      "source": [
        "human_obj_description = \"It's a dark painting with trees a moon. some clouds, a river.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkA_CO4yMFb4",
        "outputId": "3d1e8493-4aca-4811-b9ec-6d717bc4cf28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human>It's a dark painting with trees a moon. some clouds, a river.\n"
          ]
        }
      ],
      "source": [
        "print(HUMAN+\">\"+human_obj_description)\n",
        "leolaniClient._add_utterance(HUMAN, human_room_description)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is where the interactive object match comes :\n",
        "# based on \"dark painting with trees ...\", did you mean \"Painting\"?\n",
        "\n",
        "human_object_description = human_obj_description\n",
        "matched_object = interactive_object_match(api_key=api_key, human_object_description=human_object_description, unique_object_list=unique_object_list, HUMAN=HUMAN, AGENT=AGENT, leolaniClient=leolaniClient)\n",
        "print(f\"Final matched object(s): {matched_object}\")\n"
      ],
      "metadata": {
        "id": "Jg39BgRdPE0A",
        "outputId": "01e674ef-954f-4c5d-eec6-0ae206494bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ai2Thor>To be sure, would you describe your object as Painting?\n",
            "Ai2Thor>Is this correct? (yes/no): \n",
            "yes\n",
            "Human>yes\n",
            "Ai2Thor>Great! Object successfully matched.\n",
            "Final matched object(s): Painting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teleport somewhere random\n",
        "import random\n",
        "\n",
        "position = random.choice(reachable_positions)\n",
        "rotation = random.choice(range(360))\n",
        "print(\"Teleporting the agent to\", position, \" with rotation\", rotation)\n",
        "\n",
        "event = controller.step(action=\"Teleport\", position=position, rotation=rotation)\n",
        "\n",
        "#Image.fromarray(event.frame) # image for clearity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gz8CnenWUCw",
        "outputId": "7c0f2d94-e66c-4ca3-ea66-ddd010bf4e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teleporting the agent to {'x': 0.75, 'y': 0.9009997844696045, 'z': 4.25}  with rotation 264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKq23C6qMFb4",
        "outputId": "61f2b461-bb96-4f91-9850-58b3906f33d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ai2Thor>Based on the provided image, I observe a painting on the wall, but no table, chairs, or windows visible. This does not match the description of a living room with a blue table, black chairs, and a window next to balcony doors. I do not think I am in the correct room.\n"
          ]
        }
      ],
      "source": [
        "#location classificaiton:\n",
        "\n",
        "# chatgpt, do you think you are in the correct room based on human_room_description + human_room description_clarified? (maybe rotate 360 degrees, but also have to analyze 4 images then)\n",
        "\n",
        "room_classifcation = analyze_image(base64_string, api_key=api_key, prompt= f\"Imagine you are a robot looking for a certain room. Describe the room shortly. Do you think you are in the correct room based on the following description? Description: {human_room_description}, even further description: {human_room_description_clarified}, speak to me as if you have the robots point of view. Be consise in your answer.\")\n",
        "utterance = room_classifcation[0][\"choices\"][0][\"message\"][\"content\"]\n",
        "print(AGENT+\">\"+utterance)\n",
        "leolaniClient._add_utterance(AGENT, utterance)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide what to do:  teleport to another room, teleport to object instance (if there is one) or lookleft/lookright etc"
      ],
      "metadata": {
        "id": "lGqRzS5sgBpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Metadata\n",
        "\n",
        "# i see x instances of matched_object\n",
        "# teleport to matched_object[0]\n",
        "# use chatgpt to describe image\n",
        "# do so until image is found or no instances left\n",
        "\n",
        "#matched_object = \"Painting\" # placeholder\n",
        "\n",
        "object_positions = get_object_positions(controller, matched_object)\n",
        "\n",
        "for i in range(len(object_positions)):\n",
        "  position = object_positions[i]\n",
        "  event = teleport_in_front_of_object(controller, position, reachable_positions)\n",
        "\n",
        "  description = analyze_image(base64_string, api_key=api_key, prompt= f\"describe {matched_object} in great detail\")\n",
        "  utterance = description[0][\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "  print(AGENT+\">\"+utterance+\"Was this the item you were looking for?\")\n",
        "  leolaniClient._add_utterance(AGENT, utterance+\"Was this the item you were looking for?\")\n",
        "  if input(\"Type yes if so...\") == \"yes\":\n",
        "    print(HUMAN+\">\"+\"yes\")\n",
        "    leolaniClient._add_utterance(HUMAN, \"yes\")\n",
        "    break\n",
        "  else:\n",
        "      print(HUMAN+\">\"+\"no\")\n",
        "      leolaniClient._add_utterance(HUMAN, \"no\")\n",
        "      continue\n",
        "\n",
        "print(\"Teleport to new room if item isn't found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6zxeCqCOvrv",
        "outputId": "d5eba0b1-a3c1-4fbd-e9fd-6eb8d276d117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ai2Thor>The painting depicts a serene nocturnal landscape. At the center, a luminous full moon is prominent, partially obscured by dramatic, swirling clouds that add texture to the night sky. The moonlight casts an ethereal glow over the scene, highlighting the silhouettes of dense trees on either side, which frame the composition.\n",
            "\n",
            "In the middle ground, a calm body of water, possibly a pond or small lake, reflects the moonlight, contributing to the tranquil atmosphere. The reflection creates a mirror-like effect thatWas this the item you were looking for?\n",
            "Type yes if so...no\n",
            "Human>no\n",
            "Teleport to new room\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if no more instances, teleport to new room"
      ],
      "metadata": {
        "id": "htVsg7BwQDVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVLLHlrYMFb5"
      },
      "outputs": [],
      "source": [
        "##### After completion, we save the scenario in the defined emissor folder.\n",
        "leolaniClient._save_scenario()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbLveC1jLKvS"
      },
      "source": [
        "# EXAMPLE IMAGES"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOM TELEPORT"
      ],
      "metadata": {
        "id": "IFf51WX4DTwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "position = random.choice(reachable_positions)\n",
        "rotation = random.choice(range(360))\n",
        "print(\"Teleporting the agent to\", position, \" with rotation\", rotation)\n",
        "\n",
        "event = controller.step(action=\"Teleport\", position=position, rotation=rotation)\n",
        "Image.fromarray(event.frame)"
      ],
      "metadata": {
        "id": "UthmJigQDLrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMAGE WITH 2 PAINTING"
      ],
      "metadata": {
        "id": "D40jijBJDYRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event = controller.step(action=\"Teleport\", position={'x': 2.5, 'y': 0.9009997844696045, 'z': 4.5}, rotation=80)\n",
        "Image.fromarray(event.frame)"
      ],
      "metadata": {
        "id": "hZsG_wobDZtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TESTING"
      ],
      "metadata": {
        "id": "WgFX4IJ1DhhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROTATING AND REMEMBERING OBJECT LOCATIONS"
      ],
      "metadata": {
        "id": "7d42tDqvDvjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visible_objects = [obj for obj in controller.last_event.metadata[\"objects\"] if obj[\"visible\"]]\n",
        "paintings = [obj for obj in visible_objects if obj[\"objectType\"] == \"Painting\"]\n",
        "all_painting_positions = []  # To store all painting positions\n",
        "\n",
        "for _ in range(3):  # Rotate three times\n",
        "    # Get visible paintings and their positions\n",
        "    current_painting_positions = []\n",
        "    for painting in paintings:\n",
        "        print(painting[\"name\"], painting[\"position\"])\n",
        "        current_painting_positions.append(painting[\"position\"])\n",
        "\n",
        "    # Add current painting positions to the overall list\n",
        "    all_painting_positions.extend(current_painting_positions)\n",
        "\n",
        "    # Rotate the agent\n",
        "    controller.step(\"RotateRight\")\n",
        "\n",
        "    # Update visible objects and paintings for the next iteration\n",
        "    visible_objects = [obj for obj in controller.last_event.metadata[\"objects\"] if obj[\"visible\"]]\n",
        "    paintings = [obj for obj in visible_objects if obj[\"objectType\"] == \"Painting\"]\n",
        "\n",
        "print(\"All painting positions in the room:\", all_painting_positions)"
      ],
      "metadata": {
        "id": "HztOs1ffDkK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOOK UP / DOWN"
      ],
      "metadata": {
        "id": "qBWGmiSOD6-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#controller.step(\"LookDown\")\n",
        "#Image.fromarray(controller.last_event.frame)\n",
        "\n",
        "# after we take look up or down we should return to the original state, THIS IS IMPORTANT OTHERWISE IT WILL MESS WITH TELEPORTING"
      ],
      "metadata": {
        "id": "7ebhg0NmD6Ao"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "combots_venv",
      "language": "python",
      "name": "combots_venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}