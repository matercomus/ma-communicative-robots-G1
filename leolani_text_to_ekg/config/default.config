#######################################################
####### Settings that can be modified #################

## NLU
[cltl.triple_extraction]
#implementation: ConversationalAnalyzer
#implementation: CFGAnalyzer
implementation: ConversationalAnalyzer, CFGAnalyzer
intentions:
topic_intention:
topic_input : cltl.topic.text_in
topic_agent : cltl.topic.text_out
topic_output : cltl.topic.triple_extraction
topic_scenario : cltl.topic.scenario

[cltl.triple_extraction.conversational]
model_path: resources/conversational_triples
base_model: google-bert/bert-base-multilingual-cased
#base_model: albert-base-v2
language: en
threshold: 0.4
max_triples: 20
batch_size: 40

## NLG
[cltl.reply_generation]
implementations: LenkaReplier
utterance_types: question, statement, text_mention
thought_options: _overlaps, _complement_conflict, _negation_conflicts, _statement_novelty, _entity_novelty, _subject_gaps, _complement_gaps
randomness: 0.25
llamalize:True
#show_lenka:True
instruct: {'role':'system', 'content':'Paraphrase the input to simple English. If it contains names, then use these names in the paraphrase. Do not switch "you" and "I" when generating the paraphrase from the input. Be concise and do NOT include your instructions in the paraphrase.'}
#instruct: {'role':'assistant', 'content':'Paraphrase the statement or question from the user in plain Dutch.'}
model= llama3.2:1b
temperature:0.3
max_tokens:100
topic_input : cltl.topic.brain_response
topic_output : cltl.topic.text_out
intentions:
topic_intention:


#######################################################
####### Settings that should not be modified ##########

[cltl.brain]
address: http://host.docker.internal:7200/repositories/sandbox
log_dir: ./storage/rdf
clear_brain : False
topic_input : cltl.topic.knowledge
topic_output : cltl.topic.brain_response

[cltl.entity_linking]
address: http://host.docker.internal:7200/repositories/sandbox
log_dir: ./storage/rdf
implementations: NamedEntityLinker
topic_scenario : cltl.topic.scenario
topic_input : cltl.topic.triple_extraction
topic_output : cltl.topic.knowledge


[app.context]
topic_text_in: cltl.topic.text_in_ui
topic_text_forward: cltl.topic.text_in
topic_text_out: cltl.topic.text_out
topic_scenario : cltl.topic.scenario

[cltl.emissor-data]
flush_interval: 0

timeout: 15
intentions:
topic_intention:
topic_input : cltl.topic.text_in
topic_agent : cltl.topic.text_out
topic_output : cltl.topic.triple_extraction
topic_scenario : cltl.topic.scenario

[cltl.emotion_recognition]
impl: Go

[cltl.emotion_recognition.go]
#model: bhadresh-savani/bert-base-go-emotion
model: resources/bert-base-go-emotion

[cltl.emotion_recognition.events]
intentions:
topic_intention:
topic_input: cltl.topic.text_out
topic_output: cltl.topic.emotion

[cltl.dialogue_act_classification]
implementation: midas

[cltl.dialogue_act_classification.midas]
model: resources/midas-da-xlmroberta/pytorch_model.bin

[cltl.dialogue_act_classification.events]
intentions:
topic_intention:
topic_inputs : cltl.topic.text_out
topic_output : cltl.topic.dialogue_act

[cltl.chat-ui]
name: chat-ui
agent_id: leolani
external_input: True
timeout: 10

[cltl.chat-ui.events]
local: True
topic_utterance: cltl.topic.text_in_ui
topic_response: cltl.topic.text_out, text_out_chatonly
topic_scenario : cltl.topic.scenario
topic_desire : cltl.topic.desire

[cltl.context]
topic_scenario: cltl.topic.scenario

[cltl.event.kombu]
server: amqp://localhost:5672
exchange: cltl.combot
type: direct
compression: bzip2

[cltl.event_log]
log_dir: ./storage/event_log

[cltl.emissor-data]
path: ./storage/emissor

[cltl.emissor-data.event]
topics: cltl.topic.scenario, cltl.topic.text_in, cltl.topic.text_out, cltl.topic.text_out_replier,
        cltl.topic.emotion, cltl.topic.dialogue_act

